{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-multilearn in c:\\users\\bhanu\\anaconda3\\lib\\site-packages (0.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\bhanu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\bhanu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(120000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 120 seconds\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-multilearn\n",
    "\n",
    "import re\n",
    "import os\n",
    "import tqdm\n",
    "import nltk\n",
    "import pickle\n",
    "import sqlite3\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import tensorflow as tf\n",
    "from sklearn import metrics\n",
    "from tensorflow import keras\n",
    "from nltk.corpus import words\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import Word2Vec\n",
    "from itertools import combinations\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from keras.preprocessing import sequence\n",
    "from scipy.sparse import coo_matrix, hstack\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import f1_score,precision_score,recall_score,hamming_loss\n",
    "from keras.layers import Conv1D, Conv2D, Dense, Dropout, Flatten, LSTM, GlobalMaxPooling1D, MaxPooling2D, Activation, BatchNormalization\n",
    "\n",
    "%matplotlib inline\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "%autosave 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>plot_synopsis</th>\n",
       "      <th>tags</th>\n",
       "      <th>split</th>\n",
       "      <th>synopsis_source</th>\n",
       "      <th>cnt_dup</th>\n",
       "      <th>tag_count</th>\n",
       "      <th>synopsis_count</th>\n",
       "      <th>synopsis_sent_count</th>\n",
       "      <th>CleanedSynopsis</th>\n",
       "      <th>...</th>\n",
       "      <th>sentimental</th>\n",
       "      <th>storytelling</th>\n",
       "      <th>stupid</th>\n",
       "      <th>suicidal</th>\n",
       "      <th>suspenseful</th>\n",
       "      <th>thought-provoking</th>\n",
       "      <th>tragedy</th>\n",
       "      <th>violence</th>\n",
       "      <th>western</th>\n",
       "      <th>whimsical</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$</td>\n",
       "      <td>Set in Hamburg, West Germany, several criminal...</td>\n",
       "      <td>murder</td>\n",
       "      <td>test</td>\n",
       "      <td>imdb</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>648</td>\n",
       "      <td>26</td>\n",
       "      <td>set hamburg west germani sever crimin take adv...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$windle</td>\n",
       "      <td>A 6th grader named Griffin Bing decides to gat...</td>\n",
       "      <td>flashback</td>\n",
       "      <td>train</td>\n",
       "      <td>wikipedia</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>353</td>\n",
       "      <td>14</td>\n",
       "      <td>grader name griffin bing decid gather entir gr...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     title                                      plot_synopsis       tags  \\\n",
       "0        $  Set in Hamburg, West Germany, several criminal...     murder   \n",
       "1  $windle  A 6th grader named Griffin Bing decides to gat...  flashback   \n",
       "\n",
       "   split synopsis_source  cnt_dup  tag_count  synopsis_count  \\\n",
       "0   test            imdb        1          1             648   \n",
       "1  train       wikipedia        1          1             353   \n",
       "\n",
       "   synopsis_sent_count                                    CleanedSynopsis  \\\n",
       "0                   26  set hamburg west germani sever crimin take adv...   \n",
       "1                   14  grader name griffin bing decid gather entir gr...   \n",
       "\n",
       "   ...  sentimental  storytelling  stupid  suicidal  suspenseful  \\\n",
       "0  ...            0             0       0         0            0   \n",
       "1  ...            0             0       0         0            0   \n",
       "\n",
       "   thought-provoking  tragedy  violence  western  whimsical  \n",
       "0                  0        0         0        0          0  \n",
       "1                  0        0         0        0          0  \n",
       "\n",
       "[2 rows x 81 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data_with_all_tags.csv\")\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(preprocessor=lambda x: x, tokenizer = lambda x: str(x).split(\", \") )\n",
    "tag_vect = vectorizer.fit_transform(data[\"tags\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('absurd', 259), ('action', 605), ('adult comedy', 124), ('allegory', 123), ('alternate history', 98), ('alternate reality', 198), ('anti war', 108), ('atmospheric', 385), ('autobiographical', 43), ('avant garde', 213), ('blaxploitation', 73), ('bleak', 210), ('boring', 519), ('brainwashing', 103), ('christian film', 39), ('claustrophobic', 80), ('clever', 86), ('comedy', 1795), ('comic', 110), ('cruelty', 422), ('cult', 2531), ('cute', 190), ('dark', 387), ('depressing', 196), ('dramatic', 402), ('entertaining', 726), ('fantasy', 492), ('feel-good', 74), ('flashback', 2801), ('good versus evil', 793), ('gothic', 400), ('grindhouse film', 61), ('haunting', 132), ('historical', 266), ('historical fiction', 118), ('home movie', 148), ('horror', 455), ('humor', 803), ('insanity', 585), ('inspiring', 116), ('intrigue', 154), ('magical realism', 51), ('melodrama', 423), ('murder', 5375), ('mystery', 500), ('neo noir', 700), ('non fiction', 32), ('paranormal', 501), ('philosophical', 222), ('plot twist', 191), ('pornographic', 156), ('prank', 242), ('psychedelic', 1800), ('psychological', 272), ('queer', 94), ('realism', 202), ('revenge', 2313), ('romantic', 2729), ('sadist', 618), ('satire', 780), ('sci-fi', 285), ('sentimental', 225), ('storytelling', 346), ('stupid', 184), ('suicidal', 50), ('suspenseful', 1026), ('thought-provoking', 117), ('tragedy', 536), ('violence', 4138), ('western', 71), ('whimsical', 77)]\n"
     ]
    }
   ],
   "source": [
    "tags = vectorizer.get_feature_names()\n",
    "freqs = tag_vect.sum(axis=0).A1\n",
    "result = list(zip(tags, freqs))\n",
    "\n",
    "print((result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>tag_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>absurd</td>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>action</td>\n",
       "      <td>605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adult comedy</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>allegory</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alternate history</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 tag  tag_counts\n",
       "0             absurd         259\n",
       "1             action         605\n",
       "2       adult comedy         124\n",
       "3           allegory         123\n",
       "4  alternate history          98"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_counts = pd.DataFrame(result,columns=['tag','tag_counts'])\n",
    "tag_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_counts_sorted = tag_counts.sort_values(['tag_counts'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43              murder\n",
       "68            violence\n",
       "28           flashback\n",
       "57            romantic\n",
       "20                cult\n",
       "56             revenge\n",
       "52         psychedelic\n",
       "17              comedy\n",
       "65         suspenseful\n",
       "37               humor\n",
       "29    good versus evil\n",
       "59              satire\n",
       "25        entertaining\n",
       "45            neo noir\n",
       "58              sadist\n",
       "1               action\n",
       "38            insanity\n",
       "67             tragedy\n",
       "12              boring\n",
       "47          paranormal\n",
       "44             mystery\n",
       "26             fantasy\n",
       "36              horror\n",
       "42           melodrama\n",
       "19             cruelty\n",
       "24            dramatic\n",
       "30              gothic\n",
       "22                dark\n",
       "7          atmospheric\n",
       "62        storytelling\n",
       "Name: tag, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_counts = tag_counts_sorted['tag'][:30]\n",
    "tag_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_30 = list(tag_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                   murder\n",
       "1                                                flashback\n",
       "2                  suspenseful, neo noir, murder, violence\n",
       "3                                           cult, violence\n",
       "4        murder, anti war, violence, flashback, tragedy...\n",
       "                               ...                        \n",
       "13752                                   paranormal, murder\n",
       "13753                                             romantic\n",
       "13754                                     autobiographical\n",
       "13755    cruelty, murder, cult, violence, flashback, ps...\n",
       "13756                                               murder\n",
       "Name: tags, Length: 13757, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 13757/13757 [00:17<00:00, 804.22it/s]\n"
     ]
    }
   ],
   "source": [
    "#Deleting Every Tags other than TOP 30 Tags\n",
    "\n",
    "for le in tqdm(range(data.shape[0])):\n",
    "    a = []\n",
    "    b = data['tags'][le].split(\",\")\n",
    "    c = ''\n",
    "    \n",
    "    for i in range(len(b)):        \n",
    "        for j in tags_30:\n",
    "            temp = b[i].strip()  #Stripping the white-spaces present(if any) around the tag\n",
    "            \n",
    "            if temp == j:        #Comparing with the TOP 30 tags\n",
    "                a.append(j)\n",
    "        \n",
    "    if a:\n",
    "        data['tags'][le] = \", \".join(a)\n",
    "    else:\n",
    "         data['tags'][le] = np.nan        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deleting the rows that have NaN Values\n",
    "data = data.dropna() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                   murder\n",
       "1                                                flashback\n",
       "2                  suspenseful, neo noir, murder, violence\n",
       "3                                           cult, violence\n",
       "4                     murder, violence, flashback, tragedy\n",
       "                               ...                        \n",
       "13751                            comedy, sadist, flashback\n",
       "13752                                   paranormal, murder\n",
       "13753                                             romantic\n",
       "13755    cruelty, murder, cult, violence, flashback, ps...\n",
       "13756                                               murder\n",
       "Name: tags, Length: 13010, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(preprocessor=lambda x: x, tokenizer = lambda x: str(x).split(\", \"))\n",
    "tag_vect = vectorizer.fit_transform(data[\"tags\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('action', 605), ('atmospheric', 385), ('boring', 519), ('comedy', 1795), ('cruelty', 422), ('cult', 2531), ('dark', 387), ('dramatic', 402), ('entertaining', 726), ('fantasy', 492), ('flashback', 2801), ('good versus evil', 793), ('gothic', 400), ('horror', 455), ('humor', 803), ('insanity', 585), ('melodrama', 423), ('murder', 5375), ('mystery', 500), ('neo noir', 700), ('paranormal', 501), ('psychedelic', 1800), ('revenge', 2313), ('romantic', 2729), ('sadist', 618), ('satire', 780), ('storytelling', 346), ('suspenseful', 1026), ('tragedy', 536), ('violence', 4138)]\n"
     ]
    }
   ],
   "source": [
    "tags = vectorizer.get_feature_names()\n",
    "freqs = tag_vect.sum(axis=0).A1\n",
    "result = list(zip(tags, freqs))\n",
    "\n",
    "print((result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('data30.db')\n",
    "data.to_sql('data30', conn, if_exists='replace', index=False)\n",
    "train = pd.read_sql(\"Select * From data30 where split = 'train' OR split='val'\",conn)\n",
    "test =  pd.read_sql(\"Select * From data30 where split = 'test'\",conn)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[\"CleanedSynopsis\"]\n",
    "y_train= train[\"tags\"]\n",
    "\n",
    "X_test = test[\"CleanedSynopsis\"]\n",
    "y_test= test[\"tags\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_vectorizer = CountVectorizer(binary='true', max_features = 30).fit(y_train)\n",
    "y_train_multilabel = cnt_vectorizer.transform(y_train)\n",
    "y_test_multilabel = cnt_vectorizer.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of data Y_train_multilabel: (10375, 30) Y_test_multilabel: (2635, 30)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimensions of data Y_train_multilabel:\",y_train_multilabel.shape,\"Y_test_multilabel:\",y_test_multilabel.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 10375/10375 [00:02<00:00, 5118.45it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train_new = []\n",
    "\n",
    "for i in tqdm(range(len(list(X_train)))):\n",
    "    X_train_new.append(X_train[i].split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickled glove 6b 300d.pkl', 'rb') as f:\n",
    "    new_model = pickle.load(f)\n",
    "    words =  set(new_model.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 10375/10375 [00:46<00:00, 223.80it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train_multilabel = []; # the avg-w2v for each sentence/review is stored in this list\n",
    "for sentence in tqdm(X_train.values): # for each review/sentence\n",
    "    vector = np.zeros(300) # as word vectors are of zero length\n",
    "    cnt_words =0; # num of words with a valid vector in the sentence/review\n",
    "    for word in sentence.split():\n",
    "        if word in words:\n",
    "            vector += new_model[word]\n",
    "            cnt_words += 1\n",
    "    if cnt_words != 0:\n",
    "        vector /= cnt_words\n",
    "    X_train_multilabel.append(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 2635/2635 [00:12<00:00, 214.52it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test_multilabel = []; # the avg-w2v for each sentence/review is stored in this list\n",
    "for sentence in tqdm(X_test.values): # for each review/sentence\n",
    "    vector = np.zeros(300) # as word vectors are of zero length\n",
    "    cnt_words =0; # num of words with a valid vector in the sentence/review\n",
    "    for word in sentence.split():\n",
    "        if word in words:\n",
    "            vector += new_model[word]\n",
    "            cnt_words += 1\n",
    "    if cnt_words != 0:\n",
    "        vector /= cnt_words\n",
    "    X_test_multilabel.append(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>OneVsRestClassifier + SGDClassifier with LOG Loss :</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=SGDClassifier(class_weight='balanced',\n",
       "                                            loss='log'))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgl = SGDClassifier(loss='log', class_weight='balanced')\n",
    "\n",
    "clf = OneVsRestClassifier(sgl)\n",
    "clf.fit(X_train_multilabel, y_train_multilabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision1: 0.1991, recall1: 0.6642, F1-measure: 0.3064\n"
     ]
    }
   ],
   "source": [
    "prediction1 = clf.predict(X_test_multilabel)\n",
    "\n",
    "precision1 = precision_score(y_test_multilabel, prediction1, average='micro')\n",
    "\n",
    "recall1 = recall_score(y_test_multilabel, prediction1, average='micro')\n",
    "\n",
    "f1_score1 = 2*((precision1 * recall1)/(precision1 + recall1))\n",
    "\n",
    "print(\"precision1: {:.4f}, recall1: {:.4f}, F1-measure: {:.4f}\".format(precision1, recall1, f1_score1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie:  Dilwale Dulhania Le Jayenge\n",
      "Actual genre:  romantic\n",
      "Predicted tag:  ['melodrama' 'romantic' 'tragedy'] \n",
      "\n",
      "Movie:  Scooby-Doo Meets the Boo Brothers\n",
      "Actual genre:  psychedelic, horror\n",
      "Predicted tag:  ['boring' 'evil' 'fantasy' 'good' 'gothic' 'horror' 'murder' 'mystery'\n",
      " 'paranormal' 'revenge' 'versus'] \n",
      "\n",
      "Movie:  The Bodyguard\n",
      "Actual genre:  murder, violence, cult, action, romantic, melodrama, suspenseful\n",
      "Predicted tag:  ['boring' 'comedy' 'cruelty' 'dramatic' 'flashback' 'murder' 'mystery'\n",
      " 'neo' 'noir' 'revenge' 'sadist' 'suspenseful' 'violence'] \n",
      "\n",
      "Movie:  Good Night, and Good Luck.\n",
      "Actual genre:  suspenseful, flashback\n",
      "Predicted tag:  ['boring' 'dramatic' 'entertaining' 'humor' 'melodrama' 'mystery'\n",
      " 'romantic' 'satire'] \n",
      "\n",
      "Movie:  Alien\n",
      "Actual genre:  dark, boring, gothic, murder, mystery, cult, violence, horror, atmospheric, action, suspenseful\n",
      "Predicted tag:  ['boring' 'cult' 'entertaining' 'evil' 'good' 'gothic' 'horror' 'humor'\n",
      " 'insanity' 'melodrama' 'mystery' 'paranormal' 'psychedelic' 'suspenseful'\n",
      " 'tragedy' 'violence'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    k = test.sample(1).index[0]\n",
    "    print(\"Movie: \", test['title'][k]) \n",
    "    print(\"Actual genre: \",y_test[k])\n",
    "    print(\"Predicted tag: \", cnt_vectorizer.inverse_transform(prediction1[k])[0],\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> OneVsRestClassifier + SGDClassifier with HINGE Loss : </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=SGDClassifier(class_weight='balanced'))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgh = SGDClassifier(loss='hinge', class_weight='balanced')\n",
    "\n",
    "clf = OneVsRestClassifier(sgh)\n",
    "clf.fit(X_train_multilabel, y_train_multilabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision2: 0.1982, recall2: 0.6792, F1-measure: 0.3068\n"
     ]
    }
   ],
   "source": [
    "prediction2 = clf.predict(X_test_multilabel)\n",
    "\n",
    "precision2 = precision_score(y_test_multilabel, prediction2, average='micro')\n",
    "\n",
    "recall2 = recall_score(y_test_multilabel, prediction2, average='micro')\n",
    "\n",
    "f1_score2 = 2*((precision2 * recall2)/(precision2 + recall2))\n",
    "\n",
    "print(\"precision2: {:.4f}, recall2: {:.4f}, F1-measure: {:.4f}\".format(precision2, recall2, f1_score2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie:  Edge of Darkness\n",
      "Actual genre:  revenge, neo noir, murder, violence, flashback\n",
      "Predicted tag:  ['action' 'comedy' 'evil' 'gothic' 'horror' 'murder' 'mystery' 'revenge'\n",
      " 'suspenseful' 'versus' 'violence'] \n",
      "\n",
      "Movie:  Friday the 13th Part III\n",
      "Actual genre:  cult, horror, murder, violence\n",
      "Predicted tag:  ['comedy' 'cruelty' 'cult' 'entertaining' 'flashback' 'gothic' 'horror'\n",
      " 'humor' 'insanity' 'murder' 'noir' 'revenge' 'sadist' 'suspenseful'\n",
      " 'versus' 'violence'] \n",
      "\n",
      "Movie:  Paulie\n",
      "Actual genre:  entertaining\n",
      "Predicted tag:  ['melodrama' 'psychedelic'] \n",
      "\n",
      "Movie:  Trouble Along the Way\n",
      "Actual genre:  violence, flashback\n",
      "Predicted tag:  ['comedy' 'cruelty' 'entertaining' 'melodrama' 'romantic' 'satire'\n",
      " 'tragedy'] \n",
      "\n",
      "Movie:  To Be or Not to Be\n",
      "Actual genre:  satire\n",
      "Predicted tag:  ['comedy' 'cruelty' 'flashback' 'humor' 'murder' 'sadist' 'satire'\n",
      " 'violence'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    k = test.sample(1).index[0]\n",
    "    print(\"Movie: \", test['title'][k]) \n",
    "    print(\"Actual genre: \",y_test[k])\n",
    "    print(\"Predicted tag: \", cnt_vectorizer.inverse_transform(prediction2[k])[0],\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> OneVsRestClassifier + LogisticRegression:</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=LogisticRegression(class_weight='balanced'))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(class_weight='balanced')\n",
    "\n",
    "clf = OneVsRestClassifier(lr)\n",
    "clf.fit(X_train_multilabel, y_train_multilabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision3: 0.2119, recall3: 0.6575, F1-measure: 0.3205\n"
     ]
    }
   ],
   "source": [
    "prediction3 = clf.predict(X_test_multilabel)\n",
    "\n",
    "precision3 = precision_score(y_test_multilabel, prediction3, average='micro')\n",
    "\n",
    "recall3 = recall_score(y_test_multilabel, prediction3, average='micro')\n",
    "\n",
    "f1_score3 = 2*((precision3 * recall3)/(precision3 + recall3))\n",
    "\n",
    "print(\"precision3: {:.4f}, recall3: {:.4f}, F1-measure: {:.4f}\".format(precision3, recall3, f1_score3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie:  The Sign of Four: Sherlock Holmes' Greatest Case\n",
      "Actual genre:  revenge\n",
      "Predicted tag:  ['dramatic' 'flashback' 'murder' 'mystery' 'tragedy'] \n",
      "\n",
      "Movie:  Niagara, Niagara\n",
      "Actual genre:  tragedy, violence, murder\n",
      "Predicted tag:  ['boring' 'humor' 'romantic'] \n",
      "\n",
      "Movie:  Artemis Fowl\n",
      "Actual genre:  fantasy\n",
      "Predicted tag:  ['action' 'boring' 'cult' 'evil' 'fantasy' 'good' 'psychedelic'\n",
      " 'suspenseful' 'versus'] \n",
      "\n",
      "Movie:  Teenagers from Outer Space\n",
      "Actual genre:  murder\n",
      "Predicted tag:  ['action' 'boring' 'comedy' 'cult' 'evil' 'fantasy' 'flashback' 'good'\n",
      " 'humor' 'murder' 'paranormal' 'psychedelic' 'revenge' 'versus' 'violence'] \n",
      "\n",
      "Movie:  Welcome to Me\n",
      "Actual genre:  comedy, satire\n",
      "Predicted tag:  ['boring' 'comedy' 'cult' 'dramatic' 'entertaining' 'humor' 'insanity'\n",
      " 'psychedelic' 'satire'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    k = test.sample(1).index[0]\n",
    "    print(\"Movie: \", test['title'][k]) \n",
    "    print(\"Actual genre: \",y_test[k])\n",
    "    print(\"Predicted tag: \", cnt_vectorizer.inverse_transform(prediction3[k])[0],\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Conclusion</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+------------+-----------+--------+----------+\n",
      "|        Model         | Vectorizer | Precision | recall | f1_score |\n",
      "+----------------------+------------+-----------+--------+----------+\n",
      "|  SGDClassifier(log)  |  AVG W2V   |   0.199   | 0.664  |  0.306   |\n",
      "| SGDClassifier(hinge) |  AVG W2V   |   0.198   | 0.679  |  0.307   |\n",
      "|  LogisticRegression  |  AVG W2V   |   0.212   | 0.658  |   0.32   |\n",
      "+----------------------+------------+-----------+--------+----------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "tabel = PrettyTable()\n",
    "\n",
    "tabel.field_names=['Model', 'Vectorizer', 'Precision','recall','f1_score']\n",
    "\n",
    "\n",
    "tabel.add_row(['SGDClassifier(log)', 'AVG W2V',  round(precision1, 3), round(recall1, 3), round(f1_score1, 3)])\n",
    "\n",
    "tabel.add_row(['SGDClassifier(hinge)','AVG W2V', round(precision2, 3),  round(recall2, 3), round(f1_score2, 3)])\n",
    "\n",
    "tabel.add_row(['LogisticRegression','AVG W2V', round(precision3, 3), round(recall3, 3), round(f1_score3, 3)])\n",
    "\n",
    "\n",
    "print(tabel)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
